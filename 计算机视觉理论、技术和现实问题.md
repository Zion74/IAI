# 现实问题
## 图像分类面临以下问题
* 遮挡：目标物体被遮挡某一部分
* 多视角：每个物体的呈现视角是多样的
* 光照条件：像素层级上而言，不同光照对识别的影响较大
* 样本量较少：某些图像的样本难以获取，导致样本过少
* 类内差异：某种类别下的物体差异性较大，比如桌椅等，呈现形式多样，不具备统一的特征
* 类别不平衡：数据集不同类别的样本数量差异较大。
## 解决方法
### 数据不平衡
* 数据增强：对少数类样本进行图像变换，如旋转、缩放、平移、翻转等，生成更多的训练数据，增强模型的鲁棒性。
* 重采样技术：过采样和欠采样 过采样：增加少数类样本的数量，可以通过简单复制或使用合成方法，如SMOTE（Synthetic Minority Over-sampling Technique）生成新的样本。
欠采样：减少多数类样本的数量，随机删除部分样本，防止模型过度偏向多数类。
* 类别加权：样本加权和损失函数加权
* 生成式模型：SMOTE和GAN 利用GAN生成少数类的合成样本，增加数据多样性。
* 调整损失函数：
> 加权损失函数：在损失函数中对少数类赋予更高的权重，如加权交叉熵（Weighted Cross-Entropy）。
> 焦点损失（Focal Loss）：减少对易分类样本的关注，专注于困难样本的学习。
* 集成学习：训练多个模型，将结果进行融合，降低单一模型的偏差，提高对少数类的识别能力。
### 数据缺失
* 数据清洗和预处理：识别并删除缺失值过多的样本或特征，保证数据质量。
* 数据插值：线性插值、多项式插值和样条插值。（Imputation）：使用统计方法（如平均值、中位数）或预测模型（如K近邻、回归）填补缺失值。
* 特征选择：过滤式特征选择、包裹式特征选择和嵌入式特征选择。
* 数据重构：PCA和自编码器AE？
* 多任务学习
* 使用能处理缺失数据的算法：一些算法如决策树、随机森林能够直接处理部分缺失数据。
* 收集更多数据：如果可能，重新采集数据，补充缺失部分。
### 处理类别不平衡和数据缺失同时存在的问题
选择方法需要注意：数据分布的特点、模型的复杂度和训练时间等。
* 数据插值和重采样：可能导致数据分布的改变，影响准确性和稳健性。
* 类别加权和特征选择：选择合适的权重和特征，否则可能会导致模型的准确性和稳健性下降。
* 多任务学习和集成学习：考虑多个任务之间的相关性，并选择合适的集成方法，否则可能会导致模型的准确性和稳健性下降。
* 深度学习：GAN和VAE，注意模型的复杂度和训练时间，否则可能导致模型的训练困难和泛化能力下降。
### 自监督预训练方法
自监督预训练方法用来应对标签数据较少的情况
CAE，BEiT（（ViT）），MAE
* https://paperswithcode.com/paper/context-autoencoder-for-self-supervised
* https://paperswithcode.com/paper/beit-bert-pre-training-of-image-transformers
* https://paperswithcode.com/paper/masked-autoencoders-are-scalable-vision
MIM vs Contrastive Pretraining

### 端到端对象识别方法
End-to-End Object Detection with Transformers https://github.com/facebookresearch/detr 
### 数据标签较少
迁移学习（Transfer Learning）：

利用在大规模数据集（如ImageNet）上预训练的模型，将其特征提取部分应用于新任务，然后在少量数据上微调模型。
数据增强：

对现有的有标签数据进行变换，生成更多样本，缓解数据不足的问题。
半监督学习（Semi-Supervised Learning）：

结合大量未标注数据与少量标注数据，通过方法如自训练（Self-Training）、一致性正则化（Consistency Regularization）等提升模型性能。
自监督学习（Self-Supervised Learning）：

设计预任务（如图像重建、图像色彩填充），在无标签数据上学习特征，再将其应用于目标任务。
主动学习（Active Learning）：

让模型主动选择对其学习最有帮助的样本进行标注，减少标注成本。
少样本学习（Few-Shot Learning）：

使用元学习（Meta-Learning）方法，使模型能够从少量样本中学习泛化能力。
弱监督学习（Weakly Supervised Learning）：

利用不完整、噪声或粗粒度的标签进行训练，降低对精确标签的依赖。