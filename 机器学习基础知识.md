# 数学基础
可查看  [【好文导读】机器学习相关的数学参考资料](https://mp.weixin.qq.com/s/F8LTUz4R4fbEa5EdVruiWA)，具体知识参考详细内容可参考 [DeepLearningBook.pdf](https://github.com/bettermorn/IAICourse/blob/main/refermaterials/DeepLearningBook.pdf)第2，3，4章
* 高等数学
* 线性代数
* 概率论与统计学：平均数，众数，中位数，方差，条件概率，HMM模型，是统计模型，它用来描述一个含有隐含未知参数的马尔可夫过程。其难点是从可观察的参数中确定该过程的隐含参数。然后利用这些参数来作进一步的分析，例如模式识别。
# 机器学习实践过程
## 数据探索
* https://www.kaggle.com/dansbecker/basic-data-exploration
* https://www.kaggle.com/pmarcelino/comprehensive-data-exploration-with-python
预处理过程  https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing
* 处理缺失数据的方法包括使用可用特征的均值来填补缺失值、使用特殊值来填补缺失值、忽略有缺失值的样本、使用相似样本的均值填补缺失值、使用另外机器学习算法预测缺失值
* 数据最大最小规范化
## 特征工程（特征抽取）
https://scikit-learn.org/stable/auto_examples/compose/plot_feature_union.html?highlight=feature%20extraction#
* PCA 主成分分析法
* kPCA
* ICA
## 经典机器学习方法
链接https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html
参考图片 ![机器学习地图](https://github.com/bettermorn/IAICourse/blob/main/img/ml_map.png)
### 监督学习
参考https://scikit-learn.org/stable/supervised_learning.html
包括以下方法
#### 分类
* 决策树
* SVM
* 朴素贝叶斯 各个特征之间是独立的
* 最近邻居法 KNN
* C4.5
* 感知机perceptron
#### 回归
* 随机森林
* SVR
* 线性回归
* 普通最小二乘法OLS，迭代重新加权的最小二乘法
* 最近邻居法 KNN
### 无监督学习
参考 https://scikit-learn.org/stable/unsupervised_learning.html
包括以下方法
* k-means
* DBSCAN
* GMM高斯混合模型
### 强化学习
参考 
### 模型选择和评估
参考 https://scikit-learn.org/stable/model_selection.html
包括 模型评估指标
https://scikit-learn.org/stable/modules/model_evaluation.html

# 常见概念
## 理论知识
参考 [英伟达高级机器学习工程Aqeel Anwar撰写的18页精炼《机器学习面试速查表》机器学习中的关键要点]
(https://github.com/bettermorn/IAICourse/blob/main/refermaterials/ML_cheatsheets.pdf)
## 基本概念
基础知识可参考详细内容可参考 [DeepLearningBook.pdf](https://github.com/bettermorn/IAICourse/blob/main/refermaterials/DeepLearningBook.pdf)第5章
* 训练集、验证集和测试集
* 偏差用来预测与我们尝试为给定数据点预测的正确模型之间的差别。模型越简单，偏差越大。 解决偏差大的方法是在特征空间中增加特征（增加模型特征和维度都可）等。
* 方差用来衡量模型的泛化能力。方差越大，意味着模型过拟合（太复杂）。解决方差大的方法是降低模型复杂度，如正则化等。
* 过拟合、欠拟合
* 交叉熵
* 预训练模型
* 正向传播，反向传播

## 深度学习
### 主要算法模型
图片链接 https://github.com/bettermorn/IAICourse/blob/main/img/deeplearnstructure.png
![常用深度学习](https://github.com/bettermorn/IAICourse/blob/main/img/deeplearnstructure.png)
* 全连接网络 FC
# 机器学习评估指标
参考  super-cheatsheet-machine-learning.pdf  https://github.com/bettermorn/IAICourse/blob/main/refermaterials/super-cheatsheet-machine-learning.pdf
## 分类
* 混淆矩阵
* Accuracy 准确率
* Precision 精确率
* Recall 召回率
* F1 score
* ROC
* AUC
## 回归
参考 https://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics
* MAE Mean absolute error 
* MSE Mean Squared Error
* RMSE Root Mean Squared Error均方根误差
* Adjusted R方 R2     coefficient of determination
## 推荐系统
* RMSE Root Mean Squared Error均方根误差

# 机器学习训练的硬件和软件环境
## 硬件
 参考[典型深度神经网络模型训练服务器配置](https://github.com/bettermorn/IAICourse/wiki/%E5%AE%9E%E6%88%98%E6%A1%88%E4%BE%8B#%E5%85%B8%E5%9E%8B%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%85%8D%E7%BD%AE)
## 软件
* 开源机器学习框架,如Pytorch，Tensorflow等
* 依赖包，如Python，R，Matlab等
* Python程序，C/C++程序等
# 机器学习训练方法和技巧
[https://mp.weixin.qq.com/s/kXuOh4B-9r8K7zjPSIBEeQ](【机器学习基础】优化背后的数学基础)
## 视频学习材料
* 类神经网络训练不起来怎么办（一）局部最小值和鞍点 https://www.bilibili.com/video/BV1Wv411h7kN?p=20
* 类神经网络训练不起来怎么办（二）批次batch与动量 https://www.bilibili.com/video/BV1Wv411h7kN?p=21
* 类神经网络训练不起来怎么办（三）自动调整学习率 https://www.bilibili.com/video/BV1Wv411h7kN?p=22
* 类神经网络训练不起来怎么办（四）损失函数也可能有影响 https://www.bilibili.com/video/BV1Wv411h7kN?p=23
## 梯度算法的选择
数据稀疏，使用自适应方法，如Adagrad，Adadelta，RMSprop，Adam
## Critical Point: small gradient
## 选择损失函数Loss Function的方法
## Batch Normalization Batch and Momentum
## Adaptive Learning Rate optimizer

优化器用于调整初始的随机权重，并帮助模型更准确地计算目标值
学习率规划，图片链接  https://github.com/bettermorn/IAICourse/blob/main/img/LRS.png
![学习率规划](https://github.com/bettermorn/IAICourse/blob/main/img/LRS.png)
## 避免过拟合overfit的方法
## 需要调整的超参数
1. batch_size
2. 卷积核宽度
3. 神经网络的层数
4. 学习率 learning rate
决定着目标函数能否收敛到局部最小值以及何时收敛到最小值。合适的学习率能够使目标函数在合适的时间内收敛到局部最小值。当学习率设置过小时，收敛过程将变得十分缓慢。学习率设置过大时，梯度可能会在最小值附近来回震荡，甚至可能无法收敛。常用学习率调整方法包括离散下降(discrete staircase)指数减缓(exponential decay)，详细内容可参考 [DeepLearningBook.pdf](https://github.com/bettermorn/IAICourse/blob/main/refermaterials/DeepLearningBook.pdf)4.3,8.2,8.5
5. Dropout比率
6. 隐藏单元数量
# Pytorch
* Pytorch参考文档 https://pytorch.org/docs/1.9.1/nn.html
* torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)
* torch.nn.BatchNorm2d(num_features)
* torch.nn.ReLU()
* torch.nn.MaxPool2d(kernel_size, stride, padding)
* torch.nn.Linear(in_features, out_features)
* torch.nn.CrossEntropyLoss()
* torch.optim.Adam(model.parameters(), lr=0.0003, weight_decay=1e-5)





